{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import các thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm thư mục cha vào sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from config.config_university_project import ConfigUniversityProject\n",
    "from helper.logger_helper import LoggerSimple\n",
    "from helper.error_helper import show_error_info\n",
    "from helper.multithread_helper import multithread_helper\n",
    "from helper.reader_helper import load_jsonl_from_gz, store_jsons_perline_in_file, convert_json_to_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crawler_university_list.py\n",
    "> Lấy danh sách các trường đại học (url, code, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo logger từ module LoggerSimple với tên của module hiện tại\n",
    "logger = LoggerSimple(name=__name__).logger\n",
    "\n",
    "# Hàm gửi yêu cầu GET đến URL và trả về nội dung HTML của trang web\n",
    "def get_content_request(url='https://diemthi.tuyensinh247.com/diem-chuan.html'):\n",
    "    return requests.get(url).content\n",
    "\n",
    "# Hàm trích xuất dữ liệu trường đại học từ nội dung HTML\n",
    "def extract_content(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    universities_data = []\n",
    "    \n",
    "    # Lặp qua từng phần tử (li) chứa thông tin của từng trường đại học trong danh sách\n",
    "    for e_li in soup.select('#benchmarking > li'):\n",
    "        e_a = e_li.find('a')\n",
    "        url = 'https://diemthi.tuyensinh247.com' + e_a.get('href') if e_a.get('href') != '' else None\n",
    "        university_code = e_a.find('strong').get_text()\n",
    "        university_name = e_a.get_text().split('-')[-1].strip()\n",
    "        \n",
    "        # Tạo đối tượng JSON chứa thông tin của từng trường đại học\n",
    "        university_obj = {\n",
    "            'url': url,\n",
    "            'university_code': university_code,\n",
    "            'university_name': university_name\n",
    "        }\n",
    "        universities_data.append(university_obj)\n",
    "    \n",
    "    return universities_data\n",
    "\n",
    "# Hàm chính, thực hiện lấy và xử lý dữ liệu trường đại học từ trang web\n",
    "if __name__ == '__main__':\n",
    "    # URL của trang web cần lấy dữ liệu\n",
    "    url = 'https://diemthi.tuyensinh247.com/diem-chuan.html'\n",
    "    \n",
    "    # Gửi yêu cầu GET đến URL và lấy nội dung HTML\n",
    "    content_html = get_content_request(url=url)\n",
    "    \n",
    "    # Trích xuất dữ liệu trường đại học từ nội dung HTML\n",
    "    universities_data = extract_content(html=content_html)\n",
    "    logger.info(universities_data)\n",
    "    \n",
    "    # Lấy đường dẫn lưu trữ dữ liệu trường đại học từ file cấu hình\n",
    "    file_university_path = ConfigUniversityProject().file_university_path\n",
    "    \n",
    "    # Lưu dữ liệu trường đại học dưới dạng JSON line vào file\n",
    "    store_jsons_perline_in_file(jsons_obj=universities_data, file_output_path=file_university_path)\n",
    "    logger.info(f'stored data in {file_university_path}')\n",
    "    \n",
    "    # Lấy đường dẫn lưu trữ dữ liệu trường đại học dưới dạng CSV từ file cấu hình\n",
    "    file_university_CSV_path = ConfigUniversityProject().file_university_path.replace('.gz', '.csv')\n",
    "    \n",
    "    # Chuyển đổi đối tượng JSON sang file CSV\n",
    "    convert_json_to_csv(universities_data, file_university_CSV_path)    \n",
    "    logger.info(f'stored data in {file_university_CSV_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Xem thử list đã crawl về"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "university_df = pd.read_csv(f\"./common/university.csv\")\n",
    "university_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crawler_diemchuan_2020.py\n",
    "> crawl điểm chuẩn TỪNG NGÀNH CỦA TỪNG TRƯỜNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo logger từ module LoggerSimple với tên của module hiện tại\n",
    "logger = LoggerSimple(name=__name__).logger\n",
    "\n",
    "# Hàm trích xuất dữ liệu điểm chuẩn từ trang web\n",
    "def extract_data_diemchuan(url_diemchuan, university_meta, year=None):\n",
    "    # Kiểm tra nếu year không được cung cấp, khởi tạo danh sách rỗng cho diemchuan_datas\n",
    "    if year is None:\n",
    "        diemchuan_datas = []\n",
    "\n",
    "        # Lặp qua các năm từ 2019 đến 2014\n",
    "        for year in [2019, 2018, 2017, 2016, 2015, 2014]:\n",
    "            try:\n",
    "                # Tạo URL mới bằng cách thêm năm vào URL gốc\n",
    "                url_with_year = f'{url_diemchuan}?y={year}'\n",
    "                logger.info(f'prepare extract {url_with_year}')\n",
    "                \n",
    "                # Gửi yêu cầu GET đến URL\n",
    "                response = requests.get(url_with_year)\n",
    "                \n",
    "                # Kiểm tra nếu mã trạng thái của response là 200 (OK)\n",
    "                if response.status_code == 200:\n",
    "                    # Lấy nội dung HTML từ response\n",
    "                    html = response.content\n",
    "                    \n",
    "                    # Sử dụng BeautifulSoup để phân tích HTML\n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    \n",
    "                    # Lấy ra phần tử table đầu tiên từ HTML\n",
    "                    e_table = soup.select_one('table')\n",
    "                    \n",
    "                    # Lặp qua từng hàng (tr) trong table có class là 'bg_white'\n",
    "                    for e_tr in e_table.select('.bg_white'):\n",
    "                        # Lấy ra danh sách các phần tử td trong hàng (tr)\n",
    "                        e_tds = e_tr.select('td')\n",
    "                        \n",
    "                        # Lấy thông tin mã ngành từ phần tử thứ hai (index 1) trong danh sách td\n",
    "                        major_code = e_tds[1].get_text()\n",
    "                        \n",
    "                        # Lấy thông tin tên ngành từ phần tử thứ ba (index 2) trong danh sách td\n",
    "                        major_name = e_tds[2].get_text()\n",
    "                        \n",
    "                        # Lấy danh sách các nhóm môn học từ phần tử thứ tư (index 3) trong danh sách td,\n",
    "                        # tách chúng bằng dấu phẩy và loại bỏ khoảng trắng xung quanh mỗi nhóm môn học\n",
    "                        subject_groups = [subject_group.strip() for subject_group in e_tds[3].get_text().split(',')]\n",
    "                        \n",
    "                        # Lấy điểm chuẩn từ phần tử thứ năm (index 4) trong danh sách td\n",
    "                        point = e_tds[4].get_text()\n",
    "                        \n",
    "                        # Lấy ghi chú từ phần tử thứ sáu (index 5) trong danh sách td\n",
    "                        note = e_tds[5].get_text()\n",
    "                        \n",
    "                        # Với mỗi nhóm môn học trong subject_groups, tạo một đối tượng diemchuan_obj\n",
    "                        # và thêm vào danh sách diemchuan_datas\n",
    "                        for subject_group in subject_groups:\n",
    "                            diemchuan_obj = {\n",
    "                                'major_code': major_code,\n",
    "                                'major_name': major_name,\n",
    "                                'subject_group': subject_group,\n",
    "                                'point': point,\n",
    "                                'note': note,\n",
    "                                'year': year\n",
    "                            }\n",
    "                            logger.info(diemchuan_obj)\n",
    "                            diemchuan_datas.append(diemchuan_obj)\n",
    "                \n",
    "                # Nếu mã trạng thái của response không phải là 200, ghi log lỗi\n",
    "                else:\n",
    "                    logger.info(f'{response.status_code} - {url_with_year}')\n",
    "            \n",
    "            # Bắt và ghi log lỗi nếu có bất kỳ ngoại lệ nào xảy ra trong quá trình trích xuất dữ liệu\n",
    "            except Exception as e:\n",
    "                logger.error(e)\n",
    "                show_error_info(e)\n",
    "\n",
    "        # Trả về một dictionary chứa diemchuan_datas và university_meta sau khi trích xuất xong\n",
    "        return {'diemchuan_datas': diemchuan_datas, 'university_meta': university_meta}\n",
    "    \n",
    "    # Nếu year được cung cấp, trả về None\n",
    "    return None\n",
    "\n",
    "\n",
    "# Hàm thực thi lấy dữ liệu điểm chuẩn cho mỗi đối tượng trường đại học\n",
    "def method_univerisy_data(university_obj):\n",
    "    university_diemchuan_data = extract_data_diemchuan(\n",
    "        url_diemchuan=university_obj.get('url'),\n",
    "        university_meta=university_obj\n",
    "    )\n",
    "    return university_diemchuan_data\n",
    "\n",
    "\n",
    "# Hàm lấy mã trường đại học từ trang web danh sách trường đại học\n",
    "def get_university_code():\n",
    "    url = f'https://diemthi.tuyensinh247.com/danh-sach-truong-dai-hoc-cao-dang.html'\n",
    "    response = requests.get(url=url)\n",
    "    # logger.info(response.text)\n",
    "    lst_university_code = []\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Lặp qua các dòng (tr) trong bảng để lấy thông tin mã trường và URL chi tiết\n",
    "    for idx, e_tr in enumerate(soup.select('.code-shol > table > tr')):\n",
    "        if idx > 0:\n",
    "            lst_td = e_tr.select('td a')\n",
    "            code = lst_td[0].get_text()\n",
    "            url = lst_td[0].get('href')\n",
    "            if code is not None and len(code) > 0:\n",
    "                university_name = lst_td[1].get_text()\n",
    "                lst_university_code.append({\n",
    "                    'url': f'https://diemthi.tuyensinh247.com/diem-chuan/dai-hoc-cong-nghe-{code}.html',\n",
    "                    'url_info': url,\n",
    "                    'university_code': code,\n",
    "                    'university_name': university_name\n",
    "                })\n",
    "\n",
    "    return lst_university_code\n",
    "\n",
    "\n",
    "# Hàm chính, thực hiện lấy dữ liệu điểm chuẩn cho tất cả trường đại học\n",
    "if __name__ == '__main__':\n",
    "    # Lấy danh sách các trường đại học và mã trường từ trang web\n",
    "    universities = get_university_code()\n",
    "    \n",
    "    # Thực thi lấy dữ liệu điểm chuẩn cho từng trường đại học đồng thời\n",
    "    universities_diemchuan_data = multithread_helper(\n",
    "        items=universities, method=method_univerisy_data,\n",
    "        timeout_concurrent_by_second=360, debug=False,\n",
    "        max_workers=20\n",
    "    )\n",
    "\n",
    "    # Lưu dữ liệu điểm chuẩn dưới dạng JSON line vào file\n",
    "    file_university_diemchuan_path = ConfigUniversityProject().file_university_diemchuan_path\n",
    "    store_jsons_perline_in_file(jsons_obj=universities_diemchuan_data, file_output_path=file_university_diemchuan_path)\n",
    "    logger.info(f'stored file_university_diemchuan_path: {file_university_diemchuan_path}')\n",
    "\n",
    "    # Lưu dữ liệu điểm chuẩn dưới dạng CSV\n",
    "    file_university_diemchuan_CSV_path = ConfigUniversityProject().file_university_diemchuan_path.replace('.gz', '.csv')\n",
    "    convert_json_to_csv(universities_diemchuan_data, file_university_diemchuan_CSV_path)    \n",
    "    logger.info(f'stored file_university_diemchuan_path: {file_university_diemchuan_CSV_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo list để chứa các dataframe từ từng đơn vị dữ liệu\n",
    "dfs = []\n",
    "\n",
    "# Duyệt qua từng đơn vị dữ liệu\n",
    "for unit in universities_diemchuan_data:\n",
    "    # Tạo dataframe từ diemchuan_datas\n",
    "    df = pd.DataFrame(unit['diemchuan_datas'])\n",
    "    \n",
    "    # Thêm các cột từ university_meta vào dataframe\n",
    "    df['university_code'] = unit['university_meta']['university_code']\n",
    "    df['university_name'] = unit['university_meta']['university_name']\n",
    "    df['university_url'] = unit['university_meta']['url']\n",
    "    df['university_url_info'] = unit['university_meta']['url_info']\n",
    "    \n",
    "    # Thêm dataframe vào list\n",
    "    dfs.append(df)\n",
    "\n",
    "# Ghép các dataframe trong list thành một dataframe lớn\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"diemchuan.csv\",  encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
